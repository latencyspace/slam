diff --git a/croco/models/croco.py b/croco/models/croco.py
index 435def1..b60ad04 100644
--- a/croco/models/croco.py
+++ b/croco/models/croco.py
@@ -13,9 +13,9 @@ import torch.nn as nn
 torch.backends.cuda.matmul.allow_tf32 = True # for gpu >= Ampere and pytorch >= 1.12
 from functools import partial
 
-from models.blocks import Block, DecoderBlock, PatchEmbed
-from models.pos_embed import get_2d_sincos_pos_embed, RoPE2D 
-from models.masking import RandomMask
+from .blocks import Block, DecoderBlock, PatchEmbed
+from .pos_embed import get_2d_sincos_pos_embed, RoPE2D 
+from .masking import RandomMask
 
 
 class CroCoNet(nn.Module):
diff --git a/croco/models/curope/setup.py b/croco/models/curope/setup.py
index 230632e..3b73274 100644
--- a/croco/models/curope/setup.py
+++ b/croco/models/curope/setup.py
@@ -4,6 +4,9 @@
 from setuptools import setup
 from torch import cuda
 from torch.utils.cpp_extension import BuildExtension, CUDAExtension
+import subprocess
+import os
+
 
 # compile for all possible CUDA architectures
 all_cuda_archs = cuda.get_gencode_flags().replace('compute=','arch=').split()
@@ -15,6 +18,62 @@ all_cuda_archs = cuda.get_gencode_flags().replace('compute=','arch=').split()
     # '-gencode', 'arch=compute_86,code=sm_86'
 # ]
 
+
+# Initialize gcc major version
+gcc_major_version = 0
+
+# Get the version of g++
+try: 
+    # Run the command to get the g++ version
+    result = subprocess.run(['g++', '--version'], capture_output=True, text=True)
+    if result.returncode == 0:
+        # Extract version from the output
+        version_line = result.stdout.splitlines()[0]
+        version = version_line.split()[-1]  # The last element is the version
+        print(f"g++ version: {version}")
+
+        # Check if the version supports C++20 (g++ 10 and above support it)
+        gcc_major_version = int(version.split('.')[0])
+        print(f"gcc major version: {gcc_major_version}")
+    else:
+        print("Failed to get g++ version")        
+except Exception as e:
+    print(f"Failed to get g++ version: {e}")
+    
+
+
+cxx_compiler_flags = ['-O3']
+
+if os.name == 'nt':
+    cxx_compiler_flags.append("/wd4624")
+
+# Check nvcc version and set the appropriate flags.
+# Make sure that the nvcc executable is available in $PATH variables,
+# or find one according to the $CUDA_HOME variable
+try:
+    nvcc_std = subprocess.run("nvcc -h | grep -- '--std'", shell=True, capture_output=True, text=True)
+    nvcc_std_output = nvcc_std.stdout
+    
+    nvcc_flags = ['-O3','--ptxas-options=-v',"--use_fast_math"]
+    if 'c++20' in nvcc_std_output and gcc_major_version >= 10:
+        nvcc_flags.append('-std=c++20')
+        cxx_compiler_flags.append('-std=c++20')
+    elif 'c++17' in nvcc_std_output:
+        nvcc_flags.append('-std=c++17')
+        cxx_compiler_flags.append('-std=c++17')
+    elif 'c++14' in nvcc_std_output:
+        nvcc_flags.append('-std=c++14')
+        cxx_compiler_flags.append('-std=c++14')
+except Exception as e:
+    print(f"Failed to get nvcc version: {e}")
+    nvcc_flags = ['-O3','--ptxas-options=-v',"--use_fast_math"]  # Default flags if nvcc check fails
+    
+
+    
+print(f"nvcc flags: {nvcc_flags}")
+print(f"cxx flags: {cxx_compiler_flags}")
+
+
 setup(
     name = 'curope',
     ext_modules = [
@@ -25,8 +84,8 @@ setup(
                     "kernels.cu",
                 ],
                 extra_compile_args = dict(
-                    nvcc=['-O3','--ptxas-options=-v',"--use_fast_math"]+all_cuda_archs, 
-                    cxx=['-O3'])
+                    nvcc=nvcc_flags+all_cuda_archs, 
+                    cxx=cxx_compiler_flags)
                 )
     ],
     cmdclass = {
diff --git a/dust3r/heads/dpt_head.py b/dust3r/heads/dpt_head.py
index b7bdc9f..0107afe 100644
--- a/dust3r/heads/dpt_head.py
+++ b/dust3r/heads/dpt_head.py
@@ -14,7 +14,7 @@ import torch
 import torch.nn as nn
 from dust3r.heads.postprocess import postprocess
 import dust3r.utils.path_to_croco  # noqa: F401
-from models.dpt_block import DPTOutputAdapter  # noqa
+from croco.models.dpt_block import DPTOutputAdapter  # noqa
 
 
 class DPTOutputAdapter_fix(DPTOutputAdapter):
diff --git a/dust3r/model.py b/dust3r/model.py
index 7e9e81e..11a41ae 100644
--- a/dust3r/model.py
+++ b/dust3r/model.py
@@ -10,11 +10,11 @@ import huggingface_hub
 
 from .utils.misc import fill_default_args, freeze_all_params, is_symmetrized, interleave, transpose_to_landscape
 from .heads import head_factory
-from dust3r.patch_embed import get_patch_embed
-from dust3r.losses import swap, swap_ref
+from .patch_embed import get_patch_embed
+from .losses import swap, swap_ref
 
 import dust3r.utils.path_to_croco
-from models.croco import CroCoNet
+from croco.models.croco import CroCoNet
 
 import  torch.nn as nn
 
diff --git a/dust3r/patch_embed.py b/dust3r/patch_embed.py
index 07bb184..f5a1015 100644
--- a/dust3r/patch_embed.py
+++ b/dust3r/patch_embed.py
@@ -7,7 +7,7 @@
 # --------------------------------------------------------
 import torch
 import dust3r.utils.path_to_croco  # noqa: F401
-from models.blocks import PatchEmbed  # noqa
+from croco.models.blocks import PatchEmbed  # noqa
 
 
 def get_patch_embed(patch_embed_cls, img_size, patch_size, enc_embed_dim):
diff --git a/install.sh b/install.sh
index 3775ece..16b6b84 100755
--- a/install.sh
+++ b/install.sh
@@ -1,8 +1,14 @@
+#!/usr/bin/env bash
+
 # Assuming cuda is 12.x
 
 conda create -n mvdp python=3.12 -y
 conda activate mvdp
 
+python -m ensurepip --upgrade
+python -m pip install --upgrade setuptools
+
+pip install --upgrade setuptools
 pip install -r requirements.txt
 
 # installing pytorch3d: conda install directly often fails for version checking :( so installing from tar is much easier.
